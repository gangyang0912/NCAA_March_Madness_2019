{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "team_list=[]\n",
    "allteam=set()\n",
    "test_Y = []\n",
    "info = []\n",
    "feature_len = 13\n",
    "with open('WNCAATourneyDetailedResults.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    headers = next(reader, None)\n",
    "    j=0\n",
    "    for row in reader:\n",
    "        if row[0]=='2018':\n",
    "            allteam.add(row[2])\n",
    "            allteam.add(row[4])\n",
    "            if int(row[2])<int(row[4]):\n",
    "                teams=[row[2],row[4]]\n",
    "                team_list.append(teams)\n",
    "                test_Y.append(1)\n",
    "            else:\n",
    "                teams=[row[4],row[2]]\n",
    "                team_list.append(teams)\n",
    "                test_Y.append(0)\n",
    "        else:\n",
    "            row_list =[]\n",
    "            i = 0\n",
    "            for score in row:\n",
    "                if i >7 and i not in info:\n",
    "                    row_list.append(float(score))\n",
    "                i=i+1\n",
    "            if j%2 ==0:\n",
    "                lose = row_list[feature_len:]\n",
    "                win = row_list[:feature_len]\n",
    "                #diff = [lose[i]-win[i] for i in range(13)]\n",
    "                lose.extend(win)\n",
    "                #lose.extend(diff)\n",
    "                lose.append(0)\n",
    "                score_list.append(lose)\n",
    "            else:\n",
    "                lose = row_list[feature_len:]\n",
    "                win = row_list[:feature_len]\n",
    "                #diff = [win[i]-lose[i] for i in range(13)]\n",
    "                #row_list.extend(diff)\n",
    "                row_list.append(1)\n",
    "                score_list.append(row_list)\n",
    "            j = j+1\n",
    "print(len(score_list))\n",
    "with open('WRegularSeasonDetailedResults.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    headers = next(reader, None)\n",
    "    j=0\n",
    "    for row in reader:\n",
    "        row_list =[]\n",
    "        i = 0\n",
    "        #if [row[2],row[4]] in team_list or [row[4],row[2]] in team_list:           \n",
    "        for score in row:\n",
    "            if i >7 and i not in info:\n",
    "                row_list.append(float(score))\n",
    "            i=i+1\n",
    "        if j%2 ==0:\n",
    "            lose = row_list[feature_len:]\n",
    "            win = row_list[:feature_len]\n",
    "            #diff = [lose[i]-win[i] for i in range(13)]\n",
    "            lose.extend(win)\n",
    "            #lose.extend(diff)\n",
    "            lose.append(0)\n",
    "            score_list.append(lose)\n",
    "\n",
    "        else:\n",
    "            lose = row_list[feature_len:]\n",
    "            win = row_list[:feature_len]\n",
    "            #diff = [win[i]-lose[i] for i in range(13)]\n",
    "            #row_list.extend(diff)\n",
    "            row_list.append(1)\n",
    "            score_list.append(row_list)\n",
    "        j = j+1\n",
    "score_list =np.array((score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46846\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(score_list)\n",
    "print(len(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['3355', '3125', '3276', '3328', '3274', '3323', '3299', '3326', '3169', '3294', '3329', '3304', '3437', '3163', '3278', '3301', '3438', '3453', '3384', '3129', '3281', '3211', '3212', '3208', '3343', '3346', '3124', '3257', '3181', '3189', '3166', '3400', '3390', '3141', '3333', '3332', '3263', '3417', '3266', '3311', '3268', '3173', '3261', '3138', '3177', '3280', '3179', '3401', '3393', '3203', '3234', '3397', '3378', '3376', '3114', '3113', '3443', '3370', '3195', '3143', '3110', '3251', '3199', '3273'])\n"
     ]
    }
   ],
   "source": [
    "print(allteam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = score_list[:,-1]\n",
    "X = score_list[:,:-1]\n",
    "#train_X = X[:45000]\n",
    "#train_Y = Y[:45000]\n",
    "#valid_X = X[45000:]\n",
    "#valid_Y = Y[45000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation Accuracy for C = 0.001 classifier ', 0.998952331063384)\n",
      "('Training Accuracy for C = 0.001 classifier ', 0.9991111111111111)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "clf_list =[]\n",
    "C_list =[1e-3]\n",
    "for i in range(1):\n",
    "    val_acc_list=[]\n",
    "    curr_clf=[]\n",
    "    clf = SVC(kernel='linear',C=C_list[i],probability =True)\n",
    "    clf.fit(train_X,train_Y)\n",
    "\n",
    "    test_predictions = clf.predict(valid_X)\n",
    "    val_acc = [pred == y for pred,y in zip(test_predictions, valid_Y)]\n",
    "    print('Validation Accuracy for C = '+ str(C_list[i])+ ' classifier ', \n",
    "          float(sum(val_acc))/len(valid_Y))\n",
    "    \n",
    "    train_predictions = clf.predict(train_X)\n",
    "    train_acc = [pred == y for pred,y in zip(train_predictions, train_Y)]\n",
    "    print('Training Accuracy for C = '+ str(C_list[i])+ ' classifier ', \n",
    "          float(sum(train_acc))/len(train_Y))\n",
    "\n",
    "    val_acc_list.append(val_acc)\n",
    "    clf_list.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_list=[]\n",
    "allteam=set()\n",
    "with open('../WSampleSubmissionStage2.csv') as f:\n",
    "    reader = csv.reader(f, delimiter='_')\n",
    "    headers = next(reader, None)\n",
    "    for row in reader:\n",
    "        last2 = row[2].split(',')\n",
    "        team=[row[1],last2[0]]\n",
    "        allteam.add(row[1])\n",
    "        allteam.add(last2[0])\n",
    "        team_list.append(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_detail=set()\n",
    "team_dict = dict()\n",
    "team_mean_dict=dict()\n",
    "with open('WRegularSeasonDetailedResults.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    headers = next(reader, None)\n",
    "    for row in reader:\n",
    "        if row[0]=='2017':\n",
    "            team1=row[2]\n",
    "            team2=row[4]\n",
    "            if team1 in allteam:\n",
    "                if team1 not in team_dict:\n",
    "                    team_dict[team1]=[[int(row[i]) for i in range(8,8+feature_len)]]\n",
    "                else:\n",
    "                    team_dict[team1].append([int(row[i]) for i in range(8,8+feature_len)])\n",
    "            if team2 in allteam:\n",
    "                if team2 not in team_dict:\n",
    "                    team_dict[team2]=[[int(row[i]) for i in range(8+feature_len,8+2*feature_len)]]\n",
    "                else:\n",
    "                    team_dict[team2].append([int(row[i]) for i in range(8+feature_len,8+2*feature_len)])\n",
    "for t in allteam:\n",
    "    team_mean_dict[t]=np.max(np.array(team_dict[t]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X =[]\n",
    "for i,j in team_list:\n",
    "    current=list(team_mean_dict[i])\n",
    "    current.extend(team_mean_dict[j])\n",
    "    test_X.append(current)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.array(test_X)\n",
    "test_Y = np.array(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_Y=[1 if test_X[i][0]*2+test_X[i][2]+test_X[i][4]-test_X[i][13]*2-test_X[i][15]-test_X[i][17]>0 \n",
    " else 0 for i in range(len(test_Y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650793650794\n"
     ]
    }
   ],
   "source": [
    "test_acc = [x == y for x,y in zip(naive_Y, test_Y)]\n",
    "print(float(sum(test_acc))/63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990180591726081"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='linear',C=0.001,probability =True)\n",
    "clf.fit(X,Y)\n",
    "clf.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6507936507936508"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77881826,  0.01938597,  0.37927752,  0.00609028,  0.36381826,\n",
       "         0.0313458 , -0.02961228,  0.09639579,  0.0292662 , -0.04341945,\n",
       "         0.01798265,  0.01111754, -0.02637719, -0.75828745, -0.04390671,\n",
       "        -0.41841601,  0.00185671, -0.35790642, -0.03823474,  0.04678375,\n",
       "        -0.07060259, -0.02257428,  0.04246143, -0.01606106,  0.00430183,\n",
       "         0.01926071]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tree_clf = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "tree_clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6825396825396826\n"
     ]
    }
   ],
   "source": [
    "print(tree_clf.score(X,Y))\n",
    "print(tree_clf.score(test_X,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. ... 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "label_Y = clf.predict(test_X)\n",
    "print(label_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y= prob[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions.csv\", 'w')\n",
    "predictions.write(\"ID,Pred\\n\")\n",
    "k =0\n",
    "for i,j in team_list:\n",
    "    predictions.write('2019'+'_'+i+'_'+j+','+str('%.4f'%(test_Y[k]))+'\\n')\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tree_clf = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "tree_clf.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14380534 0.01272644 0.01693188 0.01027305 0.06027263 0.04360455\n",
      " 0.00915474 0.05192739 0.08636355 0.01841547 0.01588243 0.00799176\n",
      " 0.0272193  0.15275456 0.01256205 0.01628492 0.01008662 0.05999621\n",
      " 0.04855271 0.00895298 0.04633821 0.06714368 0.01906085 0.01592123\n",
      " 0.00870082 0.02907665]\n"
     ]
    }
   ],
   "source": [
    "print(tree_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
